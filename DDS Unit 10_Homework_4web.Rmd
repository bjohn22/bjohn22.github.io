---
title: "DDS-Unit 10"
author: "John Olanipekun"
date: "10/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(e1071)
library(GGally)
library(naniar)

```


```{r}
cars_df <- read_csv(file.choose())
```


```{r}
cars_df.fit <- lm(MPG~Weight, data=cars_df)
summary(cars_df.fit)
confint(cars_df.fit)
```

### 6-step hypothesis test for the slope.

```{r}
beta_1_hat <- cars_df.fit$coefficients[2]

tstat = cars_df.fit$coefficients[2]/0.0002577 #beta_1_hat / SE(beta_1_hat)
pvalue = (pt(tstat,7)) * 2 # Mult by 2 since 2 sided test
tstat
pvalue
```


###Question 1a
```{r}
cars_df %>% ggplot(aes(x=Weight, y=MPG)) + geom_point() + ggtitle("LR Model: Weight vs MPG(cars df)") + geom_smooth(method = "lm")
```

```{r}
Model_1 <- lm(MPG ~ Weight,data = cars_df)
summary(Model_1)
confint(Model_1)
```


```{r}

cars_df_2 = cars_df %>% mutate(Wt_transform = Weight^2)
Model_2 <- lm(MPG ~ Weight + Wt_transform,data = cars_df_2)
summary(Model_2)
confint(Model_2)
```



###leave one out cross validation
```{r}
#Model 1
pred_error_sq <- c(0)
for(i in 1:dim(cars_df)[1]) {
 cars_train <- cars_df[-i,]  # loop to leave one out each time
  fit <- lm(MPG ~ Weight,data = cars_train) 
  mpg_i <- predict(fit, data.frame(Weight = cars_df[i,6])) # predict each iteration observation
  pred_error_sq <- pred_error_sq + (cars_df[i,2] - mpg_i)^2 # cummulate squared prediction errors
}

SSE = var(cars_df$MPG) * ((dim(cars_df)[1])-1) #sum of squared errors

R_squared <- 1 - (pred_error_sq/SSE) # goodness of fit
R_squared

RMSE_2 = sqrt(pred_error_sq / (dim(cars_df)[1]))
RMSE_2


# Model 2
cars_df_2 = cars_df %>% mutate(Wt_transform = Weight^2)
pred_error_sq2 <- c(0)
for(i in 1:dim(cars_df_2)[1]) {
  cars_train <- cars_df_2[-i,] 
  fit <- lm(MPG ~ Weight + I(Weight^2), data = cars_train) 
  mpgs <- predict(fit, data.frame(Weight = cars_df_2[i,6])) 
  pred_error_sq2 <- pred_error_sq2 + (cars_df_2[i,2] - mpgs)^2 
}

SSE = var(cars_df_2$MPG) * ((dim(cars_df_2)[1])-1) #sum of squared errors

R_squared <- 1 - (pred_error_sq2/SSE) # Measure for goodness of fit
R_squared

RMSE_3 = sqrt((pred_error_sq2 / dim(cars_df_2)[1]))
RMSE_3

RMSE.list <- data.frame(RMSE_2=RMSE_2,RMSE_3=RMSE_3)
RMSE.list
```


```{r}
# Using model 2 let's estimate the mean mpg of the subpopulaiton of cars that weigh 2000lbs
fit_2k <- lm(MPG ~ Weight + I(Weight^2),data = cars_df)
car_2k <- data.frame(Weight = 2000)
car2k_predict <- predict(fit_2k, newdata = car_2k, interval = "confidence")
car2k_predict
```


###Question 3. 
a)Using the cars.csv dataset, We would like to assess the relationship (interpret slope parameter) between mpg and horsepower.  ###Notice that some of the horsepowers are missing.  
b)Impute (predict and insert) the missing horsepowers by fitting a regression model. 
c)You may use any of the variables as regressors EXCEPT for mps (since we will later be using horsepower to predict mpg.) 
d)Assess the relationship between the mpg and the slope.  Make sure and include estimates of your uncertainty (ie. Confidence intervals.) 
d)Use your model and imputed data to estimate the mean mpg for a car with 250 horsepower.  
 

```{r}
#3a)
cars_df %>% ggplot(aes(x=MPG, y=Horsepower)) + geom_point()+
  ggtitle("LR Model: Horsepower vs MPG(cars df)") + geom_smooth(method = "lm")
```


```{r}
#how many rows are missing. 
summary(cars_df)
gg_miss_var(cars_df)

```



```{r}
# Plots to see associations
cars_df %>% ggplot(aes(x=Acceleration, y=Horsepower)) + geom_point()+
  ggtitle("LR Model: Horsepower vs Acceleration(cars df)") + geom_smooth(method = "lm") #looks better than rest
cars_df %>% ggplot(aes(x=Weight, y=Horsepower)) + geom_point() 
cars_df %>% ggplot(aes(x=Displacement, y=Horsepower)) + geom_point()

```


```{r}
# corresponding acceleration values for missing horsepower rows
hp_miss <- cars_df %>% filter(is.na(Horsepower))

#fit the model
fit = lm(Horsepower~Acceleration, data=cars_df)

# Create the list for the missing values to be predicted
hp_acc_missing <- c(hp_miss$Acceleration[1], hp_miss$Acceleration[2])
# Create data frame with correct column names
missingData <- data.frame(Acceleration = hp_acc_missing)

pred_hp <- predict(fit, newdata = missingData)
pred_hp
```


```{r}
# # Insert our predicted horsepower
# hp_miss_insert1 <- hp_miss$Horsepower[1] <- pred_hp[1]
# hp_miss_insert1 <- hp_miss$Horsepower[2] <- pred_hp[2]
# 
# cars_df[hp_miss$Horsepower[1]] <- pred_hp[1]
# cars_df[hp_miss$Acceleration[1],]$Horsepower <- pred_hp[2]
# 
# cars_df[hp_miss_insert1[]]
# 
# # Insert our predicted horsepower
# cars_df[hp_miss[1],]$Horsepower <- pred_hp[1]
# cars_df[hp_miss[2],]$Horsepower <- pred_hp[2]
# 
# 
# 
# # Sanity check we have no more missing values
# summary(cars_df)
```



```{r}
# hp_new <- data.frame(Horsepower = 250)
# pred_hp2 <- predict(fit, newdata = hp_new)
# pred_hp
# new_fit = lm(MPG~Horsepower+Acceleration, data=cars_df)
# fit = lm(Horsepower~Acceleration, data=cars_df)
# hp_250 <- predict(new_fit, newdata = data.frame(Horsepower = 250, Acceleration=25), interval = "confidence")
# hp_250
```

